import pandas as pd
from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.ensemble import AdaBoostClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import classification_report
import warnings

warnings.filterwarnings("ignore")

# Step 1: è¯»å–æ•°æ®
df_mh = pd.read_excel("res_bal.xlsx")

# Step 2: æå–ç‰¹å¾ä¸æ ‡ç­¾
X = df_mh[['x1', 'x2', 'x3', 'x4', 'x5', 'x6' ,'x7' ,'x8', 'x9', 'x10', 
           'x11', 'x12', 'x13', 'x14', 'x15', 'cancer history', 'hypertension history', 
           'cholesterol usage', 'stroke_history', 'CVD_history', 'insulin_usage', 'APOE_status', 'sex', 
           'BMI_category', 'Family history of dementia', 'smoking', 'drinking']]
y = df_mh['ACD']

# Step 3: åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=23333, shuffle=True
)

# Step 4: ç®€å•é¢„å¤„ç†å™¨
preprocessor = ColumnTransformer([
    ('cat', 'passthrough', X.columns)
])

# Step 5: æ„å»º AdaBoost ç®¡é“
ada_model = AdaBoostClassifier(random_state=42)

pipe = Pipeline([
    ('prep', preprocessor),
    ('clf', ada_model)
])

# Step 6: å‚æ•°ç½‘æ ¼ï¼ˆå«å¼±åˆ†ç±»å™¨å†³ç­–æ ‘çš„è°ƒå‚ï¼‰
param_grid = {
    'clf__n_estimators': [50, 100, 200],
    'clf__learning_rate': [0.01, 0.1, 1.0],
    'clf__estimator': [
        DecisionTreeClassifier(max_depth=1),
        DecisionTreeClassifier(max_depth=2),
        DecisionTreeClassifier(max_depth=3)
    ]
}

# Step 7: äº¤å‰éªŒè¯æœç´¢
cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

grid_search = GridSearchCV(
    estimator=pipe,
    param_grid=param_grid,
    scoring='f1',  # ä¹Ÿå¯ä»¥æ”¹æˆ 'roc_auc'
    cv=cv,
    verbose=1,
    n_jobs=-1
)

grid_search.fit(X_train, y_train)

# Step 8: è¾“å‡ºæœ€ä¼˜å‚æ•°ä¸äº¤å‰éªŒè¯å¾—åˆ†
print("\nâœ… Best Parameters Found:")
for k, v in grid_search.best_params_.items():
    print(f"  {k}: {v}")
print(f"\nâ­ Best Cross-validated F1 Score: {grid_search.best_score_:.4f}")

# Step 9: åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°
y_pred = grid_search.best_estimator_.predict(X_test)
print("\nğŸ“Š Test Set Classification Report:")
print(classification_report(y_test, y_pred, digits=4))
